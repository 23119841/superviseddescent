{"name":"superviseddescent","tagline":"C++11 implementation of the supervised descent optimisation method","body":"# superviseddescent: A C++11 implementation of the supervised descent optimisation method\r\n\r\n\r\nsuperviseddescent is a C++11 implementation of the supervised descent method, which is a generic algorithm to perform optimisation of arbitrary functions.\r\n\r\nThere are two main advantages compared to traditional optimisation algorithms like gradient descent, L-BFGS and the like:\r\n* The function doesn't have to be differentiable. It works with arbitrary functions, for example with the HoG operator (which is a non-differentiable function)\r\n* It might be better at reaching a global optimum - give it a try!\r\n\r\nThe theory is based on the idea of _Supervised Descent Method and Its Applications to Face Alignment_, from X. Xiong & F. De la Torre, CVPR 2013 (http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6618919)\r\n\r\n## Features\r\n\r\n* Generic implementation, can be used to optimise arbitrary parameters and functions\r\n* Fast, using Eigen for matrix operations\r\n* Modern, clean C++11/14\r\n* Header only (compilation/installation only for the examples and tests)\r\n* Fully cross-platform compatible - learned models can be run even on phones\r\n\r\n## Usage\r\n\r\nIt is a header only library, and can thus be included directly into your project by just adding `superviseddescent/include` to your projects include directory and including `superviseddescent/superviseddescent.hpp`.\r\n\r\n* Tested with the following compilers: gcc-4.8.2, clang-3.5, Visual Studio 2013\r\n* Needed dependencies: Boost serialization (1.54.0), OpenCV core (2.4.3), Eigen (3.2). Older versions might work as well.\r\n\r\n## Sample code\r\n\r\n### Simple example: Approximate sin(x)\r\n\r\nDefine a function:\r\n\r\n    auto h = [](Mat value, size_t, int) { return std::sin(value.at<float>(0)); };\r\n\r\nGenerate training data (see `examples/simple_function.cpp` for the (in this case boring) code):\r\n* training labels `y_tr` in the interval [-1:0.2:1]\r\n* the inverse function values (the ground truth parameters) `x_tr`\r\n* fixed starting values of the parameters `x0` (a constant value in this case).\r\n\r\nConstruct and train the model, and (optionally) specify a callback function that prints the residual after each learned regressor:\r\n\r\n~~~{.cpp}\r\n\tvector<LinearRegressor> regressors(10);\r\n\tSupervisedDescentOptimiser<LinearRegressor> supervisedDescentModel(regressors);\r\n\tauto printResidual = [&x_tr](const cv::Mat& currentPredictions) {\r\n\t\tstd::cout << cv::norm(currentPredictions, x_tr, cv::NORM_L2) / cv::norm(x_tr, cv::NORM_L2) << std::endl;\r\n\t};\r\n\tsupervisedDescentModel.train(x_tr, x0, y_tr, h, printResidual);\r\n~~~\t\r\n\r\nThe model can be tested on test data like so:\r\n~~~{.cpp}\r\n\tMat predictions = supervisedDescentModel.test(x0_ts, y_ts, h);\r\n\tstd::cout << \"Test residual: \" << cv::norm(predictions, x_ts_gt, cv::NORM_L2) / cv::norm(x_ts_gt, cv::NORM_L2) << std::endl;\r\n~~~\r\n\r\nPredictions on new data can similarly be made with:\r\n~~~{.cpp}\r\nSupervisedDescentOptimiser::predict(cv::Mat x0, cv::Mat y, H h)\r\n~~~\r\nwhich returns the prediction result.\r\n\r\n\r\n### Landmark detection:\r\n\r\nThe `SupervisedDescentOptimiser` can be used in the same way for landmark detection. In this case,\r\n\r\n* `h` is a feature transform that extracts image features like HoG or SIFT from the image (we thus make it a function object, to store the images)\r\n* we don't use the `y` values (the so called _template_) to train, because at testing, the HoG descriptors differ for each person (i.e. each persons face looks different)\r\n* the parameters `x` are the current 2D landmark locations\r\n* the initial parameters `x0` are computed by aligning the mean landmark to a detected face box.\r\n\r\n~~~{.cpp}\r\nclass HogTransform\r\n{\r\npublic:\r\n\tHogTransform(vector<Mat> images, ...HoG parameters...) { ... };\r\n\t\r\n\tMat operator()(Mat parameters, size_t regressorLevel, int trainingIndex = 0)\r\n\t{\r\n\t\t// shortened, to get the idea across:\r\n\t\tMat hogDescriptors = extractHoGFeatures(images[trainingIndex], parameters);\r\n\t\treturn hogDescriptors;\r\n\t}\r\nprivate:\r\n\tvector<Mat> images;\r\n}\r\n~~~\r\n\r\nTraining the model is the same, except we pass an empty `cv::Mat` instead of `y` values:\r\n~~~{.cpp}\r\nHogTransform hog(trainingImages, ...HoG parameters...);\r\nsupervisedDescentModel.train(trainingLandmarks, x0, Mat(), hog, printResidual);\r\n~~~\r\n\r\nTesting and prediction work analogous.\r\n\r\nFor the documented full working example, see `examples/landmark_detection.cpp`\r\n\r\n\r\n### Pose estimation:\r\n\r\nUsing the `SupervisedDescentOptimiser` for 3D pose estimation from 2D landmarks works exactly in the same way.\r\n\r\n* `h` is the projection function that projects the 3D model to 2D coordinates, given the current parameters\r\n* `y` are the 2D landmarks, known (or detected) at training and testing time\r\n* `x` are the rotation and translation parameters (the 6 DOF of the model)\r\n* the initial parameters `x0` are all set to 0, with the exception of t_z being -2000.\r\n\r\n~~~{.cpp}\r\nclass ModelProjection\r\n{\r\npublic:\r\n\tModelProjection(Mat model) : model(model) {};\r\n\r\n\tMat operator()(Mat parameters, size_t regressorLevel, int trainingIndex = 0)\r\n\t{\r\n\t\t// parameters is a vector consisting of [R_x, R_y, R_z, t_x, t_y, t_z]\r\n\t\tprojectedPoints = projectModel(parameters);\r\n\t\treturn projectedPoints;\r\n\t};\r\nprivate:\r\n\tcv::Mat model;\r\n}\r\n~~~\r\n\r\n~~~{.cpp}\r\nModelProjection projection(facemodel);\r\nsupervisedDescentModel.train(x_tr, x0, y_tr, projection, printResidual);\r\n~~~\r\n\r\nTesting and prediction work analogous.\r\n\r\nFor the documented full working example, see `examples/landmark_detection.cpp`\r\n\r\n\r\n## Build the examples and tests\r\n\r\nBuilding of the examples and tests requires CMake>=2.8.11, OpenCV (core, imgproc, highgui, objdetect) and Boost (system, filesystem, program_options, serialization).\r\n\r\n* copy `initial_cache.cmake.template` to `initial_cache.cmake`, edit the necessary paths\r\n* create a build directory next to the `superviseddescent` folder: `mkdir build; cd build`\r\n* `cmake -C ../superviseddescent/initial_cache.cmake -G \"<your favourite generator>\" ../superviseddescent -DCMAKE_INSTALL_PREFIX=install/`\r\n* build using your favourite tools, e.g. `make; make install` or open the solution in Visual Studio.\r\n\r\n\r\n## Documentation\r\n\r\nDoxygen (insert link)\r\n\r\nThe examples and the _Class List_ in doxygen are a good place to start.\r\n\r\n## License & contributions\r\n\r\nThis code is licensed under the Apache License, Version 2.0\r\n\r\nContributions are very welcome! (best in the form of pull requests.) Please use Github issues for any bug reports, ideas, and discussions.\r\n\r\nIf you use this code in your own work, please cite the following paper: _Random Cascaded-Regression Copse for Robust Facial Landmark Detection_, Z. Feng, P. Huber, J. Kittler, W. Christmas, X.J. Wu, IEEE Signal Processing Letters, Vol: 22(1), 2015 (http://ieeexplore.ieee.org/xpl/articleDetails.jsp?tp=&arnumber=6877655).\r\n\r\n(_We are working on publishing a paper that more closely resembles this library, and we will replace the previously mentioned paper here with the new one as soon as it is published._)\r\n","google":"UA-58083469-1","note":"Don't delete this file! It's used internally to help with page regeneration."}